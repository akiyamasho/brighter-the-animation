\section{Discussion  and Next Steps}

Aside from research purposes, Brighter the Animation as a short film is more of a passion project rather than something done for networking and submission to film festivals. It is not possible to submit this short film to any festival due to copyright with Paramore, and posting it online is only possible due to Fair Use Policy. In addition, it is estimated to complete postprocessing of this short film in 5 to 6 months, which could have been used for retraining and creation of shorter films for faster feedback loop.\\\\

In addition, on the more technical side, some possible next steps include:

\begin{enumerate}
    \item As discussed in the previous sections, research on training GANs to convert freestyle render to actual anime
        \begin{itemize}
            \item How this would not be completely perfect but can be used as good initial frames ready to be cleaned up by animators
            \item One hurdle for this method is animation of clothes, which may be a separate set of inputs and outputs for the models
        \end{itemize}
    \item Research on more in-depth motion capture models~\cite{everybodyDanceNow} than OpenPose~\cite{openposeArxiv}
    \item Research on PaintsChainer~\cite{paintsChainer} retraining for colour consistency with RNNs
    \item Research feasibility of more direct pipelines~\cite{makeGirlsMoe, fullBodyAnimeGeneration, vid2vid} that convert video directly to anime
    \item Wait for NVIDIA's frame interpolation SDK~\cite{nvidiaNGXTech} and research possibilities~\cite{superSlomo}
\end{enumerate}

The major issue with using research material for application is it will take a lot of time and effort to create datasets that can be used commercially. This is why in order to apply this paper's vision, the first phase would most likely be use of the motion capture automation discussed in the previous sections rather than the deep learning libraries. Moreover, automated libraries are prone to becoming cookie-cutter processes that are not production-level, meaning the feasibility of using the library is based on using them as base frames \& automating low-level tasks rather than for actual output and the benefits of applying said base outputs for high quality, production-level output after human post-processing.